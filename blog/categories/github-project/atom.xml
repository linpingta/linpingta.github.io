<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: github project | linpingta's blog]]></title>
  <link href="http://yoursite.com/blog/categories/github-project/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2020-06-24T10:13:34+08:00</updated>
  <id>http://yoursite.com/</id>
  <author>
    <name><![CDATA[linpingta]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[tools相关项目]]></title>
    <link href="http://yoursite.com/blog/2016/08/20/tools-project/"/>
    <updated>2016-08-20T16:20:01+08:00</updated>
    <id>http://yoursite.com/blog/2016/08/20/tools-project</id>
    <content type="html"><![CDATA[<h3>tools</h3>

<p><a href="https://github.com/linpingta/tools">Github项目</a>保存了一些独立的项目和脚本，像项目名称所表示的，它们是用于提高工作效率而开发的，并且可能会在适当的时候被提取划分为独立的项目。</p>

<ol>
<li>project_maker.sh ：快速生成python常用项目的基本目录结构</li>
<li>fabfile.py ：基于<a href="http://www.fabfile.org/">fabric</a>，保存常用的操作，包括git命令和远程目录操作</li>
<li>template_maker ： 用于模板信息的快速填充，基础基于<a href="http://jinja.pocoo.org/">Jinja2</a>，主要是在工作中常用的离线模型和数据监控脚本自动生成</li>
<li>model_trainer ：用于machine learning项目的基本框架，我在参加<a href="https://www.kaggle.com/c/shelter-animal-outcomes">Kaggle竞赛</a>中使用了<a href="https://github.com/linpingta/shelter-animal-outcome">它</a></li>
<li>task_manager ： 用于离线任务的调度，基于DAG执行db任务和用户定义任务</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[离线任务调度框架]]></title>
    <link href="http://yoursite.com/blog/2016/08/19/offline-task-framework/"/>
    <updated>2016-08-19T17:28:08+08:00</updated>
    <id>http://yoursite.com/blog/2016/08/19/offline-task-framework</id>
    <content type="html"><![CDATA[<p>这两天为项目需要写了个查询工具，想想还是有些东西可以提炼出来总结的，所以这篇来描述下我做的事情。</p>

<h2>背景</h2>

<p>首先，我们把广告主的数据做了汇总，最初的数据构建是为系统使用，并不是为用户数据分析使用的（为用户分析和为系统使用的区别，简单举个例子，用户分析关心账户的名称，系统只需要它的ID），但项目里想想既然都花时间做了数据，那索性给用户导出一些分析数据（ps，很理解，但从技术角度讲，导数据的辛苦程度相比做数据也不逞多让，尤其是我们的数据开始并不是为用户准备的，还好我在导出兴趣信息的时候多想想，不仅导出了ID，还导出来兴趣名称…）。</p>

<p>开始的需求是比较模糊的，可能是广告类型的投放分析，国家的投放分析，将来很可能会扩展和定制。</p>

<h2>设计目标</h2>

<p>原则上讲，每个查询需求实际都是对应一个hive查询。如果仅仅是处理目前报告的内容，最直接的方法是理解查询需求，然后写hive脚本，导出结果。</p>

<p>这样做虽然对少量的查询比较方便，但长远考虑，有明显的问题：</p>

<ol>
<li>Hive QL包含大量重复内容，按国家维度可能是查ctr, cpa，按性别维度也是，按年龄维度也是，如果不能保存查询语句，会浪费很多时间重敲语句</li>
<li>查询对用户不友好，因为查询都是要直接写Hive QL完成，一般非技术人员没有能力这样做，最终导致需求全部叠加到技术人员身上</li>
<li>查询效率不高，这里指的不是每条Hive QL语句（好吧为了突出优点有点拼，这里并没有对Hive QL本身的优化，在最后的缺点也会提到），而是多个查询本身是可以并行执行的，如果人工输入却不得不串行执行。尤其认真说，考虑到hive查询本身是比较慢的，等待时间并不十分乐观</li>
<li>Hive数据与导出数据不一致：这点看起来很小，但实际影响很大。虽然有很多查询可以直接使用Hive QL的输出，但还有一些查询需要再对原始数据做进一步的处理。举个例子，我们的国家是按 [A,B,C]保存的，但用户最终要的是国家A，B和C分别保存的信息，忽略或者特殊处理这种合并的情况，直接把hive查询结果返回是不能满足用户需求的</li>
<li>通用操作：比如结果展现给用户的形式，通过web界面，或者通过邮件，对不同的查询是通用的</li>
</ol>


<p>为解决上述问题，我在设计上考虑框架应该实现的几个属性</p>

<ol>
<li>任务化：把每个查询作为一个独立的任务对待，通过db ORM读取再处理，这样做主要是考虑将来可能和用户做交互时，用户的查询需要持久化</li>
<li><p>任务划分：</p>

<p>   Hive查询任务，更通用的说，是和db做交互的任务</p>

<p>   用户定义任务，基于Hive查询任务或其它用户定义任务，做类似ETL或者格式规范化方面的内容</p></li>
<li><p>信息抽取：主要是针对Hive查询任务，对每个查询语句都有select, from, tablename, where等，这些语法信息是用户不关心也无需了解的，让框架来完成这些通用的内容处理，用户只填写相关的信息</p></li>
<li>任务调度：hive查询是一个高IO低CPU的操作，可以通过多线程提高效率。同时由于用户定义任务对其它任务的依赖存在，这个调度变成比较经典的有向无环图（DAG）遍历问题</li>
<li>通用处理：我依赖pandas DataFrame作为数据存储的容器，每个hive查询任务的结果会被转为DataFrame再做持久化，用户依赖任务会依赖DataFrame做进一步操作（的确多了一次落盘读盘，后续考虑改进），DataFrame本身很方便的与csv文件做转换，以及对数据处理的强大支持（嗯还没有内存放不下的数据不用考虑分布式），也会方便后续的处理</li>
</ol>


<h2>框架流程</h2>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173204.jpg" alt="Framework" /></p>

<h2>实现</h2>

<ol>
<li>Task表定义</li>
</ol>


<p>基于Django的ORM定义，Task表里把Hive QL的基本组成部分做了独立的拆分，比如dimension, metric，为方便用户输入，这些字段采用json化的list或者list of dict，这些模块后续会由Task的引擎负责检查和拼装成正确的Hive QL</p>

<pre><code>Class QueryTask(models.Model):

    id = models.IntegerField(primary\_key=True)

    name = models.CharField(max\_length=255, blank=True)

    status = models.IntegerField(blank=True, null=True)

    paused = models.IntegerField(blank=True, null=True)

    dimension = models.CharField(max\_length=1024, blank=True)

    metric = models.CharField(max\_length=1024, blank=True)

    filter = models.CharField(max\_length=1024, blank=True)

    order = models.CharField(max\_length=1024, blank=True)

    tablename = models.CharField(max\_length=1024, blank=True)

    limit = models.IntegerField(blank=True, null=True)

    start\_dt = models.IntegerField(blank=True, null=True)

    end\_dt = models.IntegerField(blank=True, null=True)

    create\_time = models.IntegerField(blank=True, null=True)

parent\_task\_ids = models.CharField(max\_length=45, blank=True)
</code></pre>

<p>后续如果有用户交互的需求，可以把用户的查询保存到db，两边都通过ORM读写。在Django项目外使用modeles.py会有一些小坑，但都不算太大，这里不再描述。</p>

<ol>
<li>任务依赖执行</li>
</ol>


<p>有向无环图的多线程遍历，我依赖的是两个队列，未执行队列放入所有入度为0的任务，已执行队列保存所有执行完毕的任务。子线程负责从未执行队列里读取任务，执行任务，向完成队列里放入任务，主线程负责从已执行队列里取任务，减少对它依赖任务的入度，并将入度为0的任务放入未执行队列。</p>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173500.jpg" alt="Iter" /></p>

<ul>
<li><p>HiveTask</p>

<p>引擎拼装HiveQL</p>

<p>查询执行</p>

<p>结果转换为DataFrame再做dump</p></li>
<li><p>UserDefineTask</p>

<p>加载依赖Task的DataFrame</p>

<p>数据处理，这里采用组合的方式，把任务的实际处理交给Worker来完成</p>

<p>保存数据</p></li>
</ul>


<h2>代码</h2>

<p><a href="https://github.com/linpingta/tools/tree/master/task_manager">Github task_manager</a></p>

<h2>问题</h2>

<p>作为一个粗糙的版本，虽然解决了开始提到的问题，但本身还是有很多的局限性：</p>

<ol>
<li>不支持table join，单个任务的查询数据只能来自一个table，这个是硬伤，对小项目可能还行，但大一点的查询就不够了。想想之前微策略做的就是根据table schema去构建table relationship，然后再封装成db无关的BI查询，还是挺敬仰的。</li>
<li>还是有很多项目耦合的内容在，比如HiveTask可以更一般化到DbTask，读取Task的方法可以考虑db之外更灵活的方式（比如xml），但这个的确是因为时间所限，还是以满足任务需求的扩展为主了。</li>
<li>用户定义任务通用内容的抽取：现在是通过把任务交给worker的方式解耦，但worker里的通用任务还不多，这点在后续的持续应用中应该会得到增加和改善。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[facebook相关项目]]></title>
    <link href="http://yoursite.com/blog/2016/07/20/facebook-related-project/"/>
    <updated>2016-07-20T16:12:16+08:00</updated>
    <id>http://yoursite.com/blog/2016/07/20/facebook-related-project</id>
    <content type="html"><![CDATA[<p>摘自<a href="https://github.com/linpingta/facebook-related">facebook-related READMD.md</a></p>

<p>1.<a href="https://github.com/linpingta/facebook-related/tree/master/facebook-ads-sdk-example">facebook-ads-sdk-example</a>
主要是提炼在项目中用到的一些Facebook API调用实例。Facebook API提供了http的封装实现，也提供了Python和PHP的SDK。在日常项目中主要会用到广告相关的API实例，关于Facebook API类型，可以看<a href="http://linpingta.cn/blog/2016/01/15/facebook-api-related/">这里</a>，在此做一个记录。</p>

<p>2.<a href="https://github.com/linpingta/facebook-related/tree/master/facebook-fan-page-fetcher">facebook-fan-page-fetcher</a>
Facebook主页粉丝的信息抓取，主要依赖CasperJS模拟翻页</p>

<p>3.<a href="https://github.com/linpingta/facebook-related/tree/master/facebook-success-creatives">facebook-success-creatives</a>
爬取Facebook成功创意的信息</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[kaggle-shelter-animal-outcome]]></title>
    <link href="http://yoursite.com/blog/2016/07/10/kaggle-shelter-animal-outcome/"/>
    <updated>2016-07-10T15:31:14+08:00</updated>
    <id>http://yoursite.com/blog/2016/07/10/kaggle-shelter-animal-outcome</id>
    <content type="html"><![CDATA[<p>这是一篇关于<a href="https://www.kaggle.com/c/shelter-animal-outcomes">Kaggle:Shelter Animal Outcomes</a>比赛的总结。</p>

<h3>比赛<a href="https://www.kaggle.com/c/shelter-animal-outcomes">背景</a></h3>

<p>比赛是基于美国一个州过去三年宠物收容所对宠物的记录数据，去预测宠物的最终命运。它本身是一个预测问题，用到的自变量包括官方提供的以下特征：</p>

<pre><code>AnimalID,Name,DateTime,OutcomeType,OutcomeSubtype,AnimalType,SexuponOutcome,AgeuponOutcome,Breed,Color
</code></pre>

<p>去预测宠物的最终命运，可能的选项包括：</p>

<pre><code>Adoption，Died，Euthanasia，Return_to_owner, Transfer
</code></pre>

<p>用到的最终评价标准是<a href="https://www.kaggle.com/c/shelter-animal-outcomes/details/evaluation">multiclass logloss</a>，简单来说就是它需要输出每个测试样本属于每类的可能性，而不是最有可能的类别，同时会更大的惩罚那些肯定性判断 （把每个记录以100%的输出错分会受到很大的惩罚），实际上最终leaderboard中那些误差大于3的提交结果应该都是输出了错误的判决结果。</p>

<h3>比赛结果</h3>

<p>截止本文完成时，我的排名是 54th/1289，比赛还有20天结束，但我已不打算进一步优化结果，最终结果应该会在结束后有所变化，我会在相应时间更新。</p>

<h3>最终方案</h3>

<h4>特征选择和处理</h4>

<p>我最终使用的特征包括：</p>

<ul>
<li>时间特征：DateTime部分被处理为5个部分

<ul>
<li> YEAR/MONTH/WEEKDAY/HOUR/UNIXTIME</li>
</ul>
</li>
<li>年龄特征：原始的年龄特征包含如“3 months”, &ldquo;2 weeks"等，全部转换为天为单位的表示，原始数据中部分动物没有年龄，相应数据被转为0（也看到过一些根据其它信息去预测年龄做填充的方案，没有尝试）</li>
<li>名称特征：原始名称转为是否有名称，名称的长度两个新特征</li>
<li>性别特征：原始性别实际包含Male/Female以及是否被阉割Intact的信息，转为Male/Female和Intact/Not Intact两个新特征</li>
<li>品种特征：首先把训练集和测试集的所有品种做统计，因为记录中每个动物都可能属于多个品种，因此把属于某品种记为1，不属于记为0</li>
<li>颜色特征：处理方法类似品种，和品种的区别是，品种会把是否包含Mix和/作为分隔符，颜色会把空格作为分隔符</li>
<li>去除处理过的原始特征，以及Animal ID信息，对测试集编码后（scikit-learn fit_transform），采用相同的编码方式处理训练集</li>
</ul>


<h4>模型选择</h4>

<p>最终我使用的是由ChenTianqi（中国人，非常厉害）开发的<a href="https://github.com/dmlc/xgboost">XGBoost</a>作为学习模型，如XGBoost名称所示，它本身就是一种boosting方法，在我的测试中，它的效果要比RandomForest更好。</p>

<p>最终的参数：</p>

<pre><code>param = {'max_depth':11, 'eta':0.03, 'subsample':0.75, 'colsample_bytree':0.85, 'eval_metric':'mlogloss', 'objective':'multi:softprob', 'num_class':5, 'verbose':1}
num_round = 400
dtrain = xgb.DMatrix(train_x, label=train_y)
clf = xgb.train(param, dtrain, num_round)
</code></pre>

<p>关于XGBoost的介绍，首先参考它的<a href="https://github.com/dmlc/xgboost/tree/master/python-package">Github</a>（包含使用的Example），其次关于参数调优可以参考<a href="http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">这篇文章</a></p>

<p>PS. XGBoost本身是基于C开发的，它提供了R和Python两种接口，就我看到的情况看，R语言的接口相比Python会更方便一些，如果将来有机会，我还会对XGBoost做更多的探索。</p>

<h3>我做过的尝试</h3>

<p>我相信最终的方案并不是这次比赛的全部收获（或者更直白的说，只是很少一部分），作为第一个真正认真参加的Kaggle比赛，我想记录一个Kaggle新手在处理问题的过程，对阅读博客的人有更多帮助。</p>

<p>下面的尝试我大致按时间记录：
1. 第一次：几乎没有处理原始数据，只是去除无用的字段（比如OutcomeSubtype, AnimalID）用RandomForest直接训练，得到的logloss是13.8：这里的问题在于，没有看清题目的损失评价方法是logloss，直接用的分类树而不是回归树，给出一堆0，1结果
2. 第二次：仅仅是更新损失评价方法和树类别，logloss下降到3.4
3. 第三次：开始真正意义上的数据清理，包括如下尝试：</p>

<pre><code>* 处理Age信息，把年月日数据统一为天表示
* 尝试把猫和狗作为独立的对象分别训练
* 处理Datetime，转为年月，weekday以及几点钟
* 添加本地的cross validation
这个阶段结束后，logloss下降到1.8
</code></pre>

<p>4.第四次：回归模型参数，发现在RandomForest中使用的树数量和树深度都太少太浅，调整参数，logloss下降到0.98
5.第五次：增加名称信息，增加Sex分隔处理，处理品种和颜色是否混合的信息
6.第六次：开始使用Grid Search做参数空间的搜索，经过参数优化后，logloss大概在0.82左右
7.第七次：用XGBoost替换RandomForest，调整相关参数，之后又对年龄特征做了细化，logloss达到0.75左右
8.这之后其实有一段很长的时间，logloss并没有什么提高，这期间我尝试过用KNN（没有太多调优，误差在0.98），尝试过<a href="http://linpingta.cn/blog/2016/06/25/model-stacking/#disqus_thread">模型融合</a>，还尝试过使用场外特征，但是都没有在logloss上面有明显的改善（场外还是有一些改善，但并不合法还是放弃了）
9.最后的改进：在特征中加入UnixDateTime特征，以及把XGBoost算法从scikit-learn版本更改为它的原生版本，logloss达到0.72，再更新参数和训练周期(num_round)，最佳logloss达到0.708。</p>

<h3>项目代码</h3>

<p><a href="https://github.com/linpingta/shelter-animal-outcome">Github地址</a></p>

<h3>经验和教训</h3>

<p>大致来说，logloss的改进经过“特征处理->模型调参->特征处理”这样不断循环的过程，在模型大致可行的前提下，特征工程，指的是发现新特征，或者处理原有特征，会对结果又明显的改善，但是这句话的前提是模型大致可行，也就是说模型本身的参数，以及选择哪个模型，仍然是非常重要的。
结论性的来说，模型和特征是解决问题的两个重要因素，哪个弄不动了就试试另外一个，通常会不断提升结果。
这次也对模型融合做了一些尝试，效果不是很好，但相信以后会有更好的结果。</p>

<h3>关于Kaggle</h3>

<p>其实关于kaggle有没有用，网上有很多说法，但主要的说法是，你要指望通过kaggle去做data science，是不太靠谱的。因为它的数据集本身是比较干净的（虽然也有缺省值要处理），问题的目标也是比较清晰的（损失函数都告诉你了嘛），而实际工作中，包括我自己遇到的问题里，如何去定义问题，去处理数据，往往是问题中最困难的（其实定义问题是最困难的，很多问题并没有那么明显的损失函数去描述）。
我觉得这种说法是很有道理的，所以我想说kaggle的比赛结果并不能说明什么，但为什么我还愿意参加这样的比赛，我想是基于以下的理由：</p>

<pre><code>1. 接触那些与工作内容完全不同的问题：Kaggle上有各类机器学习的问题，分类回归聚类，图像NLP，一个人的实际工作中其实很难接触到太多方面，这里是个好途径
2. 学习新的模型，新的方法：恰恰是因为不用去做数据提取和预处理的工作，可以让人更专注于模型本身。我可以学习到新的模型，新的调参方法，这些或许在将来会给予工作帮助
3. 它本身有一定的意义。Kaggle比赛不能排除作弊，但它毕竟是一个很明确的问题。从我不长时间的面试和被面试经验看，机器学习相关的项目经验，由于业务本身特点（内部工具或者多人合作），其实是很难在面试很短时间内描述清楚的。Kaggle的比赛至少可以说明一个人在运用模型方面的基本能力是get了，因为Kaggle的比赛是一定包括训练集测试集特征处理交叉验证这些基础的方法的。我不认为Kaggle的优胜者一定是一个好的data engineer，但至少说明他在数据这个大领域的某些方面还不错。
</code></pre>

<p>最后说一点，除了以上的经验，我根据一般模型训练的步骤开发了一套<a href="https://github.com/linpingta/tools/tree/master/model_trainer">框架</a>，可以方便以后使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Weixin相关项目]]></title>
    <link href="http://yoursite.com/blog/2016/06/18/weixin-related-project/"/>
    <updated>2016-06-18T21:11:48+08:00</updated>
    <id>http://yoursite.com/blog/2016/06/18/weixin-related-project</id>
    <content type="html"><![CDATA[<p>1.<a href="https://github.com/linpingta/weixin-api-related/tree/master/wx-api-alpha">wx-api-alpha</a></p>

<pre><code>最开始的设想是想仿照Facebook Ads Python SDK封装一套weixin的API，但实际完成度很低，项目里主要包含的是一个token的自动获取（微信默认每一段时间token就会失效，因此每次调用前需要先确认token有效，这点可以通过token自动获取简化），以及基本requests对http调用的封装。
</code></pre>

<p>2.<a href="https://github.com/linpingta/weixin-api-related/tree/master/dm-message-server/weixin_server">dm-message-server</a></p>

<pre><code>微信对用户输入的交互示例
以及与微信相关的任务管理，包括显示，编辑，创建和删除等
</code></pre>

<p>3.<a href="https://github.com/linpingta/weixin-api-related/tree/master/weixin-monitor">weixin-monitor</a></p>

<pre><code>微信报警模块的简单示例
</code></pre>
]]></content>
  </entry>
  
</feed>
