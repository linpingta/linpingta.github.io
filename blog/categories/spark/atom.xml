<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: spark | linpingta's blog]]></title>
  <link href="http://yoursite.com/blog/categories/spark/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2020-06-24T10:13:34+08:00</updated>
  <id>http://yoursite.com/</id>
  <author>
    <name><![CDATA[linpingta]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[广告成本（CPA）预测模型初步]]></title>
    <link href="http://yoursite.com/blog/2016/10/23/cpa-perdiction-with-spark/"/>
    <updated>2016-10-23T09:57:40+08:00</updated>
    <id>http://yoursite.com/blog/2016/10/23/cpa-perdiction-with-spark</id>
    <content type="html"><![CDATA[<h2>广告成本（CPA）预测模型初步</h2>

<h3>实验背景</h3>

<p>通过投放管理，我们收集了相当数量广告主的广告投放数据。Facebook广告在设定时包含相当数量的定向信息，最常用的比如国家，性别和年龄。广告投放往往在相同定向上有相似的表现效果（比如同一款游戏投放美国和东南亚，前者的CPA一定比后者高），因此我们可以尝试用历史数据预测广告CPA的未来表现。</p>

<h3>实验目标</h3>

<p>希望依据广告投放的历史数据，构建回归模型，预测广告当前的CPA表现，指导模型投放。</p>

<h3>分析工具</h3>

<p>考虑到数据源直接存储在Hive中，同时也考虑数据量可能的增长预测，我们采用Spark做数据处理和模型预测方面的工作。
Spark本身是基于RDD实现的内存计算框架，它的一个重要应用在于处理机器学习中迭代问题的优化，相对应的库为Spark ml。多说一句的是 ，Spark版本更新较快，相应机器学习库存在ml和mllib两个版本，分别基于DataFrame和RDD处理数据。实际上，DataFame可以视为对RDD的封装，在1.3版本前，它也被称为schema RDD，即包含元数据描述的RDD。
我们选择ml和DataFrame操作数据，因为它们在后续更新的优先级会高于mllib。</p>

<h3>数据源介绍</h3>

<p>我们把离线模块拥有的数据源信息划分为广告维度，产品维度，时间维度，广告特征维度，定向特征维度，创意维度和统计维度这几个部分。
技术上，它们来自Hive表offlin_data，表内容每天会定时加载更新。</p>

<p>广告维度字段 (字段名称我只补充了部分需要说明的，因为大多数字段都是自表意的)
| id | description |
|&mdash;|:&mdash;|:&mdash;:|&mdash;:|
|Bm_id  |Business Manager|
|Account_id|   <br/>
|Campaign_id|  <br/>
|Adset_id| <br/>
|Ad_id|</p>

<p>产品维度</p>

<table>
<thead>
<tr>
<th> id </th>
<th style="text-align:left;"> description </th>
</tr>
</thead>
<tbody>
<tr>
<td>Application_id / promotion_url</td>
<td style="text-align:left;">    App链接</td>
</tr>
<tr>
<td>Product_type</td>
<td style="text-align:left;">  App类型，提取自user_os</td>
</tr>
<tr>
<td>Game_type</td>
<td style="text-align:left;"> 应用类型，需单独处理</td>
</tr>
</tbody>
</table>


<p>时间维度
| id | description |
|&mdash;|:&mdash;|:&mdash;:|&mdash;:|
|Dt / start_dt / end_dt|    数据分析的最小单位是天|</p>

<p>广告特征维度</p>

<table>
<thead>
<tr>
<th> id </th>
<th style="text-align:left;"> description </th>
</tr>
</thead>
<tbody>
<tr>
<td>Bid_amount</td>
<td style="text-align:left;">    广告的出价</td>
</tr>
<tr>
<td>Daily_budget</td>
<td style="text-align:left;">  广告的日预算，如果设置</td>
</tr>
<tr>
<td>Lifetime_budget</td>
<td style="text-align:left;">   广告的生命周期预算，如果设置</td>
</tr>
<tr>
<td>Is_autobid</td>
<td style="text-align:left;">    是否是autobid</td>
</tr>
<tr>
<td>Relevance_score</td>
<td style="text-align:left;">   广告的质量得分</td>
</tr>
<tr>
<td>Page_id</td>
<td style="text-align:left;">   广告使用的page信息</td>
</tr>
</tbody>
</table>


<p>定向特征维度
| id | description |
|&mdash;|:&mdash;|:&mdash;:|&mdash;:|
|Min_age / max_age <br/>
|gender<br/>
|country   <br/>
|city   我们抓取了city信息，如果有的话
|Custom_audience   <br/>
|Connection<br/>
|Exclude_connection<br/>
|Interests <br/>
|…   <br/>
完整的定向特征保持与PE上adset可编辑的定向内容完全一致，这里不一一列出</p>

<p>创意维度
| id | description |
|&mdash;|:&mdash;|:&mdash;:|&mdash;:|
|Video_id / video_image_url |Video的FB ID
|Image_url / image_hash |Image的链接</p>

<p>统计维度
| id | description |
|&mdash;|:&mdash;|:&mdash;:|&mdash;:|
|Impression / reach<br/>
|Clicks<br/>
|Actions   <br/>
|Spend <br/>
|Unique_click/unique_impression</p>

<p>创意分为视频和图片两类，出价方式分为使用autobid和不使用autobid，本次分析只针对图片类创意，不使用autobid的游戏类广告。</p>

<p>Spark中对数据加载通过Hive QL，如下语句：</p>

<pre><code>conf = SparkConf().setAppName("offline-train")
sc = SparkContext(conf=conf)
hc = HiveContext(sc)

# generate your query_sql
df = hc.sql(query_sql)
</code></pre>

<h3>数据预处理</h3>

<p>1.考虑在数据量极小时，CPA的绝对值没有意义（比如一共只有几十美分的花费就带来安装并不能说明说明当前定向下真实成本就是几十美分），因此我们过滤掉单日花费小于20$的广告，因为我们认为在太少的花费下，CPA是不可信的。
2.对autobid的广告，数据源中会把对应的bid_amount设置为0，同时，广告在应用和游戏上通常也有着不同的表现，目前我们没有方法直接判断一个promotion_url是游戏还是应用（后续拟添加支持），但通常应用的出价范围和游戏不一致，因此我们选择bid_amount>50美分的ad作为样本对象。
3.回归中较常用的误差衡量方式是RMSE，一些异常点可能对RMSE的结果影响较大，根据经验，因此我们选择天级别实际cpa小于20的ad作为样本，将cpa大于20的ad视为异常数据。
4.因为我们只分析图片创意，因此我们选择image_url非空的case
5.因为后续OneHotEncoder不接受空字符串，因此把空字符串均转为”unknown”</p>

<p>经过以上过滤后，7天内有效数据量占总记录条数的比例约为2%。</p>

<h3>特征工程</h3>

<p>首先，我们经数据预处理后，从数据源中选择了如下原始特征：</p>

<p>dimensions部分</p>

<pre><code>    Image_url
    Dt
    Age_min
    Age_max
    Is_autobid
    Genders
    Product_type
    Countries
    Bid_amount
    Daily_budget
    Connection_ids
    Custom_audience_ids
    Excluded_connection_ids
    Interest_ids
    Billing_event
</code></pre>

<p>metric部分</p>

<pre><code>    Spend
    Mobile_app_install
</code></pre>

<p>metric部分只用于计算cpa，通过Hive定义的udf完成。</p>

<pre><code>UdfFunc = udf(udf_func, FloatType())
df = df.withColumn(“cpa”, UdfFunc(df[“spend”], df[“mobile_app_install”]))
</code></pre>

<p>1.把age_min和age_max合并为age_avg，然后在最终输入模型的训练特征中去除age_min和age_max：</p>

<pre><code>age_avg = (age_min + age_max) / 2
</code></pre>

<p>2.把dt信息转为weekday，在最终模型中去除dt信息：</p>

<pre><code>def weekday(dt):
    if not dt:
        return '-1'
    import datetime
    d = datetime.datetime.strptime(str(dt), '%Y%m%d')
    return int(d.weekday())
</code></pre>

<p>3.对于如countries, connection_ids，可能在一条记录中包含多个国家或多个connection，我们只抽取其中第一条记录视为记录的代表：</p>

<pre><code>def countries_fill(countries):
    if (not countries) or (countries == 'null'):
        return 'unknown'
    countries = countries.replace('::',',')
    return countries[0]
</code></pre>

<h3>特征编码</h3>

<p>由于Spark.ml的树模型不接受字符串类型输入（与scikit-learn一致），因此我们对所有字符特征都作为string to index的转换，然后做了one hot encoder。</p>

<pre><code># countries -&gt; one-hot encoder, category
countries_indexer = StringIndexer(inputCol="countries", outputCol="countries_index", handleInvalid="skip")
countries_onehot_indexer = OneHotEncoder(dropLast=False, inputCol="countries_index", outputCol="countries_vec")
</code></pre>

<p>Spark.ml支持流水线（pipeline）的数据处理模式，需要我们把相关处理特征加入pipeline中。</p>

<pre><code>stages = [
        countries_indexer, countries_onehot_indexer,
]
# finally
pipeline = Pipeline(stages=stages)
</code></pre>

<p>最终将cpa视为label，将其它特征视为features：</p>

<pre><code>assembler = VectorAssembler(
    inputCols = feature_columns,
    outputCol = "features"
)
stages.append(assembler)
</code></pre>

<h3>模型选择</h3>

<p>在Spark.ml的默认模型中，我们选择随机森林（Random Forest）作为回归预测模型。虽然从效果上讲，Random Forest可能不如其它ensemble方法，但它是强于decision tree的，考虑模型的可解释性，以及实现的便利性，我们直接选择RandomForestRegressor作为回归模型。</p>

<p>对于Random Forest，较为重要的两个参数是单棵树的深度(max depth of tree)和树的个数(num of trees)，对这两个参数通过grid-search确定合理值。</p>

<pre><code># do cross-validation
paramGrid = ParamGridBuilder()\
    .addGrid(random_forest.maxDepth, [3, 5, 7, 9])\
    .addGrid(random_forest.numTrees, [100])\
    .build()
evaluator = RegressionEvaluator()

cv = CrossValidator(estimator=pipeline,
    estimatorParamMaps=paramGrid,
    evaluator=evaluator,
    numFolds=2)
model = cv.fit(df)
print model.avgMetrics
</code></pre>

<p>最终模型选择14天数据为训练数据，1天数据为预测数据，RMSE大约在1.59
预测cpa和实际cpa输出样例（前50条）：</p>

<table>
<thead>
<tr>
<th>        prediction</th>
<th style="text-align:left;">    label</th>
<th style="text-align:center;">            features</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.5217560913620043</td>
<td style="text-align:left;">1.4385713</td>
<td style="text-align:center;">(1042,[0,1,2,3,17&hellip;</td>
</tr>
<tr>
<td>2.3752164632800854</td>
<td style="text-align:left;">5.8022223</td>
<td style="text-align:center;">(1042,[0,1,2,3,19&hellip;</td>
</tr>
<tr>
<td> 2.411657767271753</td>
<td style="text-align:left;">3.0307143</td>
<td style="text-align:center;">(1042,[0,1,2,3,42&hellip;</td>
</tr>
<tr>
<td>3.6899882643509763</td>
<td style="text-align:left;">3.5722387</td>
<td style="text-align:center;">(1042,[0,1,2,3,50&hellip;</td>
</tr>
<tr>
<td> 4.092828817916082</td>
<td style="text-align:left;">2.2818182</td>
<td style="text-align:center;">(1042,[0,1,2,3,55&hellip;</td>
</tr>
<tr>
<td> 4.197697715305045</td>
<td style="text-align:left;"> 3.366192</td>
<td style="text-align:center;">(1042,[0,1,2,3,52&hellip;</td>
</tr>
<tr>
<td> 4.197697715305045</td>
<td style="text-align:left;">4.0157895</td>
<td style="text-align:center;">(1042,[0,1,2,3,46&hellip;</td>
</tr>
<tr>
<td> 4.197697715305045</td>
<td style="text-align:left;">3.4369998</td>
<td style="text-align:center;">(1042,[0,1,2,3,49&hellip;</td>
</tr>
<tr>
<td> 4.071716257839271</td>
<td style="text-align:left;"> 1.917647</td>
<td style="text-align:center;">(1042,[0,1,2,3,44&hellip;</td>
</tr>
<tr>
<td>3.9807423344404818</td>
<td style="text-align:left;">2.6338665</td>
<td style="text-align:center;">(1042,[0,1,2,3,42&hellip;</td>
</tr>
<tr>
<td>3.9807423344404818</td>
<td style="text-align:left;">3.5842857</td>
<td style="text-align:center;">(1042,[0,1,2,3,42&hellip;</td>
</tr>
<tr>
<td> 4.177470410349176</td>
<td style="text-align:left;">1.9453847</td>
<td style="text-align:center;">(1042,[0,1,2,3,42&hellip;</td>
</tr>
<tr>
<td> 4.071716257839271</td>
<td style="text-align:left;">1.8128395</td>
<td style="text-align:center;">(1042,[0,1,2,3,44&hellip;</td>
</tr>
<tr>
<td>1.9035986906299776</td>
<td style="text-align:left;">1.7442857</td>
<td style="text-align:center;">(1042,[0,1,2,3,22&hellip;</td>
</tr>
<tr>
<td>13.808040417768252</td>
<td style="text-align:left;">   16.058</td>
<td style="text-align:center;">(1042,[0,1,2,3,27&hellip;</td>
</tr>
<tr>
<td>14.168610809794092</td>
<td style="text-align:left;">  14.8975</td>
<td style="text-align:center;">(1042,[0,1,2,3,18&hellip;</td>
</tr>
<tr>
<td>11.971184107912041</td>
<td style="text-align:left;">    10.89</td>
<td style="text-align:center;">(1042,[0,1,2,3,19&hellip;</td>
</tr>
<tr>
<td>11.962558073010637</td>
<td style="text-align:left;">     8.89</td>
<td style="text-align:center;">(1042,[0,1,2,3,30&hellip;</td>
</tr>
<tr>
<td>2.3169264529890903</td>
<td style="text-align:left;"> 2.916579</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.3169264529890903</td>
<td style="text-align:left;">3.2772727</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.5221071103811983</td>
<td style="text-align:left;">6.3782606</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.3389387340836876</td>
<td style="text-align:left;">2.1707425</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.7074257356107376</td>
<td style="text-align:left;">1.8128985</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.8675894765662682</td>
<td style="text-align:left;">3.8840384</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.241272660641193</td>
<td style="text-align:left;">4.9881816</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.268769985708979</td>
<td style="text-align:left;"> 2.851852</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>  2.16831561899445</td>
<td style="text-align:left;">3.3324242</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>  2.16831561899445</td>
<td style="text-align:left;"> 4.152222</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.292079711361142</td>
<td style="text-align:left;">3.9308271</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.292079711361142</td>
<td style="text-align:left;">2.6325426</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.8987393163009587</td>
<td style="text-align:left;">2.9423833</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.8987393163009587</td>
<td style="text-align:left;">2.2502885</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.1668434345072054</td>
<td style="text-align:left;">4.4953847</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.1668434345072054</td>
<td style="text-align:left;">2.8725274</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.268769985708979</td>
<td style="text-align:left;"> 2.570139</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.268769985708979</td>
<td style="text-align:left;"> 3.188125</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>  2.16831561899445</td>
<td style="text-align:left;">1.9479818</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>  2.16831561899445</td>
<td style="text-align:left;">3.9414287</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.3165876740390625</td>
<td style="text-align:left;"> 2.620024</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.318769978387125</td>
<td style="text-align:left;">1.6355883</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.146834324914294</td>
<td style="text-align:left;">1.5435859</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.146834324914294</td>
<td style="text-align:left;">2.0905683</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.361828624187834</td>
<td style="text-align:left;">2.4541378</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.237440741142636</td>
<td style="text-align:left;">3.7431035</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td> 2.237440741142636</td>
<td style="text-align:left;">1.1768421</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.2990649947244433</td>
<td style="text-align:left;">  2.50875</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>  2.35518238420236</td>
<td style="text-align:left;"> 3.223077</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.9192676385516463</td>
<td style="text-align:left;">3.5867856</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>1.9192676385516463</td>
<td style="text-align:left;">2.2514102</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
<tr>
<td>2.3522288292714277</td>
<td style="text-align:left;">3.7342856</td>
<td style="text-align:center;">(1042,[0,1,2,3,11&hellip;</td>
</tr>
</tbody>
</table>


<h3>后续展望</h3>

<p>就模型本身而言，在各个方面都还有很大的改进空间：</p>

<pre><code>处理数据集本身的局限性
特征工程的方法
模型的选择和参数调试
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark常用概念]]></title>
    <link href="http://yoursite.com/blog/2016/09/16/spark-normal-concepts/"/>
    <updated>2016-09-16T10:54:51+08:00</updated>
    <id>http://yoursite.com/blog/2016/09/16/spark-normal-concepts</id>
    <content type="html"><![CDATA[<p>这篇博客主要涵盖了我在Spark学习中遇到的一些较为重要的概念。这些概念对我理解服务运行有很大的帮助，但由于网上有更详细更精彩的解释，我在这里并不打算全面的覆盖每个概念的解释，而主要起到对概念索引的作用。如果需要具体查找相关概念，还请在网上搜索相关名词。</p>

<p>概念列表
1. RDD与DataFrame：RDD是Spark计算的基础单位，它是一个逻辑概念，从程序的角度讲，所有操作都包含在RDD transformation和RDD action之上。DataFrame又称为schema RDD，意为包含元数据定义的RDD，它自1.6版本引入，后续会成为MLlib操作的首选对象。
2. action与transformation：RDD的操作都可以划分为这两类行为。它们的区别在于，transformation的输出是另外一个RDD，action的输出是其它对象或文件。执行上讲，transformation操作并不会立即执行，它是lazy的，Spark只是记录它的执行路径，只有遇到action时，相关操作才会转为physical execution plan具体执行。
3. driver, executor, master, worker：有时候会容易把driver, master或者executor，worker混淆。首先，对Spark程序而言，它只有driver和executor两个概念，driver负责生成tasks，executor负责具体执行。master和worker是cluster manager的概念，cluster manager负责对集群的资源进行调度，因此无论driver还是executor，都是执行在worker node上的，同时driver和master的任务目标也是不同的。
4. cluster manager类别：Spark支持三种集群管理方式：standalone，Mesos和YARN，YARN里面又分为yarn-client和yarn-cluster两种模式。Mesos和YARN都是成熟的集群管理方式，在生产环境里用的更多些，也方便与Hadoop任务贡献资源，standalone是单独的集群，意味对资源的单独占用
5. yarn-client和yarn-cluster的区别：主要在于driver的未知，yarn-client的driver是运行的客户端的，如果客户端关闭，任务就结束了，yarn-cluster的driver是运行在集群ApplicatoinMaster上的，任务运行时不要求客户端active
6. ApplicationMaster是什么：这是YARN的一个概念，所有任务必须通过ApplicationMaster作为容器包装， 它负责与ResourceManager交互，申请资源
7. driver-memory和executor-memory应该如何设置：driver-memory通常不需要太大，因为driver上面不执行任务，但如果有collect操作还是要大一些，一般设置1G即可，executor-memory根据任务实际的需要可以大一些
8. Spark执行参数设置：董有一系列<a href="https://www.iteblog.com/archives/1672">博客</a>，涉及参数设置还有调优，对原理也讲得很多，建议看看
9. DAG：有向无环图，Spark执行任务的基础，每次遇到action时，它会根据依赖，去找所有祖先节点的任务，构成一个DAG后，再作为job执行
10. job,stage和task：相比于RDD是Spark的逻辑概念，job,stage和stask都是Spark物理执行中的概念。它们基本是包含关系，每个job可能会被拆分为多个stage，每个stage里包含多个task。它们都可以在Spark Web UI上查看执行情况。具体而言，每个action操作都会产生一个单独的job，job会根据情况划分stage，主要是根据任务是否可以在本地执行，或者说是否有shuffle，每次shuffle都会划分出两个stage，同一个stage里的任务可以并行执行parallel。
11. shuffle：从底层讲，Spark任何执行也可以划分为map类和reduce类，比如filter,map都是在本地操作，而reduceByKey则需要对key进行归并。每次reduce操作都会引起shuffle，shuffle包括shuffle read和shuffle write，都是对磁盘的操作，因此从性能角度出发，尽可能减少shuffle操作可以提高执行效率
12. Spark Web UI：查看任务执行情况，包括job, stage, storage, task，其中stage里面可以看到执行DAG情况，通常在提交任务机器的4040端口查看，查看只能在任务执行区间，任务结束后不能再查看
13. Spark SQL和Hive QL：区别还是在底层实现框架上，Spark SQL是采用Spark执行，而Hive QL是把任务翻译成map-reduce执行
14. Spark比Hadoop快：并不是绝对的，在某些任务上Spark不一定比Hadoop快。Spark快的主要原因在于：</p>

<pre><code>    1.Spark把任务视为一个DAG执行，在任务间可以并行化，Hadoop是把每个任务作为map-reduce执行，并不会对任务间优化
    2.Spark的任务主要是在内存里计算的，而map-reduce每次都会有shuffle操作，因此对于迭代类任务，大量的读写会较慢
    3.Spark的executor在初始化时启动jvm，后续不需要每次都重新启动，Hadoop的jvm会为每个任务新启动，初始化时间消耗也是一个因素
</code></pre>

<p>15.Spark cache或者persist：默认情况下，每个action都会重新计算它链路上所有的RDD，但如果有RDD被多次重复使用，可以使用rdd.persist()来做缓存，避免重复计算
16.Spark与内存：Spark并不要求把所有数据都放到内存里才能计算</p>

<p>暂时想到的是这么多，在此记录下。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Xgboost-Spark应用调研]]></title>
    <link href="http://yoursite.com/blog/2016/09/01/xgboost-spark/"/>
    <updated>2016-09-01T23:04:15+08:00</updated>
    <id>http://yoursite.com/blog/2016/09/01/xgboost-spark</id>
    <content type="html"><![CDATA[<p>官方文档 <a href="https://spark.apache.org/docs/2.0.0/ml-guide.html">https://spark.apache.org/docs/2.0.0/ml-guide.html</a>
本文假设已正常安装spark和scala，其中spark为standalone模式。</p>

<p>1.官方的介绍资料在<a href="http://dmlc.ml/2016/03/14/xgboost4j-portable-distributed-xgboost-in-spark-flink-and-dataflow.html">这里</a></p>

<p>2.下载地址：<a href="https://github.com/dmlc/xgboost">https://github.com/dmlc/xgboost</a></p>

<p>3.样例运行
(1) 在完成上述下载后，进入git项目根目录，执行make编译源文件生成lib/xgboost.so
    在这一步中，如果遇到宏引用未定义错误，可能需要在对应文件中添加include或者宏定义。
(2) 进入jvm-package目录，执行mvn package编程生成jar包
    不同于spark官网的scala项目管理文件用sbt完成，xgboost项目采用maven完成包管理，如果没有安装maven，需先安装maven2
(3) 运行纯scala示例
    在上一步完成后，jvm-package/xgboost-example/target目录下已经生成了对应的jar文件，进入xgboost-example目录，以BoostFromPrediction为例，执行如下操作：</p>

<pre><code>scala -cp target/xgboost4j-example-0.7-jar-with-dependencies.jar ml.dmlc.xgboost4j.scala.example.BoostFromPrediction
</code></pre>

<p>在这里遇到的问题可能是”scala error: main method is not static“，原因是scala的main函数需要放在object对象下面而不是class对象下面来实现static，因此解决方法是把对应源文件的class对应替换为object并重新编译打包，正常的输出如下:</p>

<pre><code>[0]     train-error:0.046522    test-error:0.042831
[1]     train-error:0.022263    test-error:0.021726
</code></pre>

<p>(4) 运行spark示例
完成上述编译后，在spark目录下提交任务：</p>

<pre><code>./bin/spark-submit --master local[4] --class ml.dmlc.xgboost4j.scala.example.spark.DistTrainWithSpark /home/test/xgboost/jvm-packages/xgboost4j-example/target/xgboost4j-example-0.7-jar-with-dependencies.jar 30 1 /home/test/xgboost/demo/data/agaricus.txt.train /home/test/xgboost/demo/data/agaricus.txt.test /home/test/xgboost/demo/data/result
</code></pre>

<p>xgboost目前只有一个spark示例，上述各项参数的含义在源码中有清晰描述.</p>
]]></content>
  </entry>
  
</feed>
