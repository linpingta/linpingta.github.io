<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: python | linpingta's blog]]></title>
  <link href="http://yoursite.com/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2020-06-24T10:13:34+08:00</updated>
  <id>http://yoursite.com/</id>
  <author>
    <name><![CDATA[linpingta]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[离线任务调度框架]]></title>
    <link href="http://yoursite.com/blog/2016/08/19/offline-task-framework/"/>
    <updated>2016-08-19T17:28:08+08:00</updated>
    <id>http://yoursite.com/blog/2016/08/19/offline-task-framework</id>
    <content type="html"><![CDATA[<p>这两天为项目需要写了个查询工具，想想还是有些东西可以提炼出来总结的，所以这篇来描述下我做的事情。</p>

<h2>背景</h2>

<p>首先，我们把广告主的数据做了汇总，最初的数据构建是为系统使用，并不是为用户数据分析使用的（为用户分析和为系统使用的区别，简单举个例子，用户分析关心账户的名称，系统只需要它的ID），但项目里想想既然都花时间做了数据，那索性给用户导出一些分析数据（ps，很理解，但从技术角度讲，导数据的辛苦程度相比做数据也不逞多让，尤其是我们的数据开始并不是为用户准备的，还好我在导出兴趣信息的时候多想想，不仅导出了ID，还导出来兴趣名称…）。</p>

<p>开始的需求是比较模糊的，可能是广告类型的投放分析，国家的投放分析，将来很可能会扩展和定制。</p>

<h2>设计目标</h2>

<p>原则上讲，每个查询需求实际都是对应一个hive查询。如果仅仅是处理目前报告的内容，最直接的方法是理解查询需求，然后写hive脚本，导出结果。</p>

<p>这样做虽然对少量的查询比较方便，但长远考虑，有明显的问题：</p>

<ol>
<li>Hive QL包含大量重复内容，按国家维度可能是查ctr, cpa，按性别维度也是，按年龄维度也是，如果不能保存查询语句，会浪费很多时间重敲语句</li>
<li>查询对用户不友好，因为查询都是要直接写Hive QL完成，一般非技术人员没有能力这样做，最终导致需求全部叠加到技术人员身上</li>
<li>查询效率不高，这里指的不是每条Hive QL语句（好吧为了突出优点有点拼，这里并没有对Hive QL本身的优化，在最后的缺点也会提到），而是多个查询本身是可以并行执行的，如果人工输入却不得不串行执行。尤其认真说，考虑到hive查询本身是比较慢的，等待时间并不十分乐观</li>
<li>Hive数据与导出数据不一致：这点看起来很小，但实际影响很大。虽然有很多查询可以直接使用Hive QL的输出，但还有一些查询需要再对原始数据做进一步的处理。举个例子，我们的国家是按 [A,B,C]保存的，但用户最终要的是国家A，B和C分别保存的信息，忽略或者特殊处理这种合并的情况，直接把hive查询结果返回是不能满足用户需求的</li>
<li>通用操作：比如结果展现给用户的形式，通过web界面，或者通过邮件，对不同的查询是通用的</li>
</ol>


<p>为解决上述问题，我在设计上考虑框架应该实现的几个属性</p>

<ol>
<li>任务化：把每个查询作为一个独立的任务对待，通过db ORM读取再处理，这样做主要是考虑将来可能和用户做交互时，用户的查询需要持久化</li>
<li><p>任务划分：</p>

<p>   Hive查询任务，更通用的说，是和db做交互的任务</p>

<p>   用户定义任务，基于Hive查询任务或其它用户定义任务，做类似ETL或者格式规范化方面的内容</p></li>
<li><p>信息抽取：主要是针对Hive查询任务，对每个查询语句都有select, from, tablename, where等，这些语法信息是用户不关心也无需了解的，让框架来完成这些通用的内容处理，用户只填写相关的信息</p></li>
<li>任务调度：hive查询是一个高IO低CPU的操作，可以通过多线程提高效率。同时由于用户定义任务对其它任务的依赖存在，这个调度变成比较经典的有向无环图（DAG）遍历问题</li>
<li>通用处理：我依赖pandas DataFrame作为数据存储的容器，每个hive查询任务的结果会被转为DataFrame再做持久化，用户依赖任务会依赖DataFrame做进一步操作（的确多了一次落盘读盘，后续考虑改进），DataFrame本身很方便的与csv文件做转换，以及对数据处理的强大支持（嗯还没有内存放不下的数据不用考虑分布式），也会方便后续的处理</li>
</ol>


<h2>框架流程</h2>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173204.jpg" alt="Framework" /></p>

<h2>实现</h2>

<ol>
<li>Task表定义</li>
</ol>


<p>基于Django的ORM定义，Task表里把Hive QL的基本组成部分做了独立的拆分，比如dimension, metric，为方便用户输入，这些字段采用json化的list或者list of dict，这些模块后续会由Task的引擎负责检查和拼装成正确的Hive QL</p>

<pre><code>Class QueryTask(models.Model):

    id = models.IntegerField(primary\_key=True)

    name = models.CharField(max\_length=255, blank=True)

    status = models.IntegerField(blank=True, null=True)

    paused = models.IntegerField(blank=True, null=True)

    dimension = models.CharField(max\_length=1024, blank=True)

    metric = models.CharField(max\_length=1024, blank=True)

    filter = models.CharField(max\_length=1024, blank=True)

    order = models.CharField(max\_length=1024, blank=True)

    tablename = models.CharField(max\_length=1024, blank=True)

    limit = models.IntegerField(blank=True, null=True)

    start\_dt = models.IntegerField(blank=True, null=True)

    end\_dt = models.IntegerField(blank=True, null=True)

    create\_time = models.IntegerField(blank=True, null=True)

parent\_task\_ids = models.CharField(max\_length=45, blank=True)
</code></pre>

<p>后续如果有用户交互的需求，可以把用户的查询保存到db，两边都通过ORM读写。在Django项目外使用modeles.py会有一些小坑，但都不算太大，这里不再描述。</p>

<ol>
<li>任务依赖执行</li>
</ol>


<p>有向无环图的多线程遍历，我依赖的是两个队列，未执行队列放入所有入度为0的任务，已执行队列保存所有执行完毕的任务。子线程负责从未执行队列里读取任务，执行任务，向完成队列里放入任务，主线程负责从已执行队列里取任务，减少对它依赖任务的入度，并将入度为0的任务放入未执行队列。</p>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173500.jpg" alt="Iter" /></p>

<ul>
<li><p>HiveTask</p>

<p>引擎拼装HiveQL</p>

<p>查询执行</p>

<p>结果转换为DataFrame再做dump</p></li>
<li><p>UserDefineTask</p>

<p>加载依赖Task的DataFrame</p>

<p>数据处理，这里采用组合的方式，把任务的实际处理交给Worker来完成</p>

<p>保存数据</p></li>
</ul>


<h2>代码</h2>

<p><a href="https://github.com/linpingta/tools/tree/master/task_manager">Github task_manager</a></p>

<h2>问题</h2>

<p>作为一个粗糙的版本，虽然解决了开始提到的问题，但本身还是有很多的局限性：</p>

<ol>
<li>不支持table join，单个任务的查询数据只能来自一个table，这个是硬伤，对小项目可能还行，但大一点的查询就不够了。想想之前微策略做的就是根据table schema去构建table relationship，然后再封装成db无关的BI查询，还是挺敬仰的。</li>
<li>还是有很多项目耦合的内容在，比如HiveTask可以更一般化到DbTask，读取Task的方法可以考虑db之外更灵活的方式（比如xml），但这个的确是因为时间所限，还是以满足任务需求的扩展为主了。</li>
<li>用户定义任务通用内容的抽取：现在是通过把任务交给worker的方式解耦，但worker里的通用任务还不多，这点在后续的持续应用中应该会得到增加和改善。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Celery用于监控微信报警]]></title>
    <link href="http://yoursite.com/blog/2016/07/01/celery-weixin-monitor/"/>
    <updated>2016-07-01T23:47:00+08:00</updated>
    <id>http://yoursite.com/blog/2016/07/01/celery-weixin-monitor</id>
    <content type="html"><![CDATA[<p>应用场景</p>

<p>广告系统会根据业务需求（比如预算到期，创意被拒，账户被封等）给用户发送微信提醒。</p>

<p>之前的实现方法是，由业务模块负责把数据推送到由redis简单构成的消息队列中，然后有一个集中处理模块定期去采集消息队列中的信息，发送给对应用户。</p>

<p>这样实现虽然简单，但是有一些问题的：
1. 定期集中处理相当于是采用轮询的方式查看队列，首先在没有数据时，轮询操作本身是一种浪费资源（尽管在这个场景下浪费不大），其次轮询意味着固定的时间周期，如果时间周期过短肯定是资源消耗增加，如果时间周期过长一方面是报警不及时（你预算都停了半天才告诉我，还不如我自己去看对吧），同时也会让很多报警一次性的发送给用户（微信突然响个不停）
2. redis的队列本身没有重试，也不会保存信息，换句话说，如果采集模块出bug了，这些数据就是丢了，前期报警数据本身没有那么重要（因为不是直接涉及钱的数据），但丢数据从技术角度还是应该解决的问题。
3. 代码复杂度，用redis的话，每个业务服务都得redis客户端对吧，那就要负责开关。每个业务服务通常习惯使用不同的名称（与业务本身相关），这点得和采集模块保持一致，但如果模块多了呢，或者说这种信息定义在业务代理里，本身查看和更新也非常不方便。</p>

<p>Celery可以解决的问题
1.不是同步非阻塞了，是异步查询。执行效率变高了，用户不用等了，如果业务量级大，还是会有延迟，但你可以定义不同优先级的队列处理，用户基本是及时收到报警信息。
2.任务本身可以重试，相关消息也可以根据需要保存。
3.采集模块简化为一个函数，业务调用模块调用函数（实际是发送消息到队列），两侧均不再需要直接接触redis。</p>

<p>另外也研究了Celery用于定时任务管理的功能，考虑对其它语言的接受程度和系统稳定性，还是决定使用公司内部开发的调度系统。关于定时任务的应用，以后有机会再做介绍。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Celery常见问题]]></title>
    <link href="http://yoursite.com/blog/2016/06/28/celery-frequent-asked-question/"/>
    <updated>2016-06-28T09:43:58+08:00</updated>
    <id>http://yoursite.com/blog/2016/06/28/celery-frequent-asked-question</id>
    <content type="html"><![CDATA[<p>问题节选自<a href="http://docs.celeryproject.org/en/latest/faq.html">Frequently Asked Questions</a>，只挑选了一些感觉比较重要的回答，也掺杂了一些自己的理解，有兴趣请阅读<a href="http://docs.celeryproject.org/en/latest/faq.html">原文</a>。</p>

<p>1.Celery的适用场景</p>

<pre><code>(1) 后台运行的场景。比如web应用中，需要快速返回结果给用户，以求得更好的用户体验，但任务本身还需要在后台运行，此时很适合使用Celery。
(2) 周期性执行的任务
</code></pre>

<p>还有几点可以视为Celery的属性</p>

<pre><code>(1) 异步执行，包含重试
(2) 分布式
(3) 并行
</code></pre>

<p>2.Celery的依赖</p>

<p>作者在这里吐槽了下对依赖过多的批评："The rationale behind such a fear is hard to image"，软件本身应该避免重复造轮子，而且有像pip这样的包管理工具，安装依赖本身并不是一件头疼的事情。</p>

<p>这里我想吐槽下依赖的问题：最近在工作里用到Celery发现启动后遇到<a href="http://linpingta.cn/blog/2016/06/24/celery-problem-1/">Socket_connect_timeout错误</a>，最终排查后，发现是kombu的版本略新，而redis的版本略旧导致了问题，所以说依赖如果能够保证版本一致还好，但如果同一模块不同版本间升级较多，依赖者就要麻烦了。</p>

<p>回过头来看看Celery的依赖：</p>

<pre><code>(1) kombu：一个python消息库，据说在openstack项目中也有使用
(2) billard：一个对python自带multiprocessing模块功能升级的模块
(3) pytz：时区管理
</code></pre>

<p>另外Django也提供Celery的使用支持。</p>

<p>3.Celery算是一个轻量级服务吗
是的，但同样需要考虑CPU和IO的[优化]。(<a href="http://docs.celeryproject.org/en/latest/userguide/optimizing.html#guide-optimizing">http://docs.celeryproject.org/en/latest/userguide/optimizing.html#guide-optimizing</a>)</p>

<p>4.Celery的序列化方式
默认是pickle，但同样支持yaml, json等其它格式。</p>

<p>5.Celery适用的web框架
不仅是Django，也包括其它</p>

<p>6.Celery的broker选择
推荐使用RabbitMQ或者支持AMQP协议的消息队列，但是Redis，或者其它数据库（MongoDB, 关系型数据库）也是可以选择的。
补充下，在这里Redis的支持应该是好于其它数据库（无论是关系还是非关系），另外也有文章说最好不要用关系型数据库作为Celery的broker，所以其实主要的选择就是两点：RabbitMQ或者Redis。
像我们工作的环境，RabbitMQ并没有安装，因此我们选择Redis作为broker。</p>

<p>7.Celery支持多语言么
支持
这点我还没有什么应用，这里不乱说了，有兴趣请看<a href="http://docs.celeryproject.org/en/latest/faq.html">原文</a>。</p>

<p>8.如何清除队列里的任务
调用purge命令。
如果是清除所有任务，可以：</p>

<pre><code>celery -A proj purge
</code></pre>

<p>如果是清除指定队列中的任务，可以：</p>

<pre><code>celery -A proj amqp queue.purge &lt;queue name&gt;
</code></pre>

<p>9.如何根据taskID获取任务执行的结果
调用task.AsyncResult命令</p>

<pre><code>result = my_task.AsyncResult(task_id)
result.get()
</code></pre>

<p>10.可以以root身份运行celery么
一定不要这样，可能的安全问题会导致风险。</p>

<p>11.如何在一个任务调用完后执行另外一个任务
依赖<a href="http://docs.celeryproject.org/en/latest/userguide/canvas.html">Canvas</a>中定义的操作符，在执行完A后执行B：</p>

<pre><code>do A | do B
</code></pre>

<p>12.如何取消正在执行的任务</p>

<pre><code>result = add.apply_async(args=[2, 2], countdown=120)
result.revoke()
</code></pre>

<p>13.如何将指定任务发送到指定server
    使用<a href="http://docs.celeryproject.org/en/latest/userguide/routing.html">路由</a></p>

<p>14.Celery支持优先操作么
不支持消息级别的优先级操作，Celery对优先级操作的支持是通过把不同优先级的任务发送到不同的任务路由实现。</p>

<p>15.可以指定时间执行任务么
类似crontab的调用：</p>

<pre><code>from celery.schedules import crontab
from celery.task import periodic_task

@periodic_task(run_every=crontab(hour=7, minute=30, day_of_week="mon"))
def every_monday_morning():
    print("This is run every Monday morning at 7:30")
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Celery got an unexpected keyword argument 'socket_connect_timeout']]></title>
    <link href="http://yoursite.com/blog/2016/06/24/celery-problem-1/"/>
    <updated>2016-06-24T10:52:17+08:00</updated>
    <id>http://yoursite.com/blog/2016/06/24/celery-problem-1</id>
    <content type="html"><![CDATA[<p>这是一次问题的错误记录，celery在机器A上可以正常工作，但在机器B上启动时</p>

<pre><code>celery worker -A app --loglevel=info
</code></pre>

<p>会遇到如下问题：</p>

<pre><code>  File "/usr/local/lib/python2.7/site-packages/celery-3.1.23-py2.7.egg/celery/worker/consumer.py", line 376, in connect
    callback=maybe_shutdown,
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/connection.py", line 369, in ensure_connection
    interval_start, interval_step, interval_max, callback)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/utils/__init__.py", line 246, in retry_over_time
    return fun(*args, **kwargs)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/connection.py", line 237, in connect
    return self.connection
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/connection.py", line 742, in connection
    self._connection = self._establish_connection()
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/connection.py", line 697, in _establish_connection
    conn = self.transport.establish_connection()
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/virtual/__init__.py", line 809, in establish_connection
    self._avail_channels.append(self.create_channel(self))
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/virtual/__init__.py", line 791, in create_channel
    channel = self.Channel(connection)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/redis.py", line 464, in __init__
    self.client.info()
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/utils/__init__.py", line 325, in __get__
    value = obj.__dict__[self.__name__] = self.__get(obj)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/redis.py", line 908, in client
    return self._create_client(async=True)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/redis.py", line 861, in _create_client
    return self.AsyncClient(connection_pool=self.async_pool)
  File "/usr/local/lib/python2.7/site-packages/kombu-3.0.35-py2.7.egg/kombu/transport/redis.py", line 882, in __init__
    self.connection = self.connection_pool.get_connection('_')
  File "/usr/local/lib/python2.7/site-packages/redis/connection.py", line 455, in get_connection
    connection = self.make_connection()
  File "/usr/local/lib/python2.7/site-packages/redis/connection.py", line 464, in make_connection
    return self.connection_class(**self.connection_kwargs)
TypeError: __init__() got an unexpected keyword argument 'socket_connect_timeout'
</code></pre>

<p>网上关于此问题的主要讨论来自：
<a href="https://github.com/celery/celery/issues/2903">https://github.com/celery/celery/issues/2903</a></p>

<p>但感觉大多数讨论并没有指明问题的解决方法。重新查看错误日志，看到问题最终出现在 /redis/connection.py中，即python redis客户端模块中，其中Connection类的构造函数如下：</p>

<pre><code>class Connection(object):
"Manages TCP communication to and from a Redis server"
description_format = "Connection&lt;host=%(host)s,port=%(port)s,db=%(db)s&gt;"

def __init__(self, host='localhost', port=6379, db=0, password=None,
             socket_timeout=None, encoding='utf-8',
             encoding_errors='strict', decode_responses=False,
             parser_class=DefaultParser):
    self.pid = os.getpid()
    self.host = host
    self.port = port
    self.db = db
    self.password = password
    self.socket_timeout = socket_timeout
    self.encoding = encoding
    self.encoding_errors = encoding_errors
    self.decode_responses = decode_responses
    self._sock = None
    self._parser = parser_class()
</code></pre>

<p>再对比可以运行机器中相应源代码：</p>

<pre><code>class Connection(object):
    "Manages TCP communication to and from a Redis server"
    description_format = "Connection&lt;host=%(host)s,port=%(port)s,db=%(db)s&gt;"

    def __init__(self, host='localhost', port=6379, db=0, password=None,
                 socket_timeout=None, socket_connect_timeout=None,
                 socket_keepalive=False, socket_keepalive_options=None,
                 retry_on_timeout=False, encoding='utf-8',
                 encoding_errors='strict', decode_responses=False,
                 parser_class=DefaultParser, socket_read_size=65536):
        self.pid = os.getpid()
        self.host = host
        self.port = int(port)
        self.db = db
        self.password = password
        self.socket_timeout = socket_timeout
        self.socket_connect_timeout = socket_connect_timeout or socket_timeout
        self.socket_keepalive = socket_keepalive
        self.socket_keepalive_options = socket_keepalive_options or {}
        self.retry_on_timeout = retry_on_timeout
        self.encoding = encoding
        self.encoding_errors = encoding_errors
        self.decode_responses = decode_responses
</code></pre>

<p>可以看到在新版本的redis中才会支持socket_connect_timeout字段。</p>

<p>因为问题的解决办法是：升级redis到2.10以上版本</p>

<pre><code>pip install redis --upgrade
</code></pre>

<p>这个解决方案我也补充在 <a href="https://github.com/celery/celery/issues/2903">https://github.com/celery/celery/issues/2903</a> 的最后了。s</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Keras深度学习框架(介绍)]]></title>
    <link href="http://yoursite.com/blog/2016/06/08/keras-introduction/"/>
    <updated>2016-06-08T22:14:42+08:00</updated>
    <id>http://yoursite.com/blog/2016/06/08/keras-introduction</id>
    <content type="html"><![CDATA[<p>keras是一个高层次的深度学习模块，底层依赖Theano(默认)或TensorFlow调用，封装了Theano中的功能，简化深度学习相关功能的调用。</p>

<p>Sequential : 用于组合一系列layers，是keras最基础的类。
最常用的网络定义模式如下：</p>

<pre><code>models = Sequential()
models.add(Dense(32, input_dim=784)) # 添加model1
models.add(Activation('relu')) # 添加model2
# 添加其它model
...
# 定义模型
models.compile(optimizer='sgd',loss='categorical_crossentropy', metric=['accuracy'])

# 训练模型
models.fit(train_x, train_y, nb_epoch, batch_size)

# 输出预测
y_pred = models.predict_class(test_x)
</code></pre>

<p>通过非常清晰简单的方式，我们就可以定义一个深度学习网络(models.add)，定义它的优化方式(models.compile)，然后训练模型(models.fit)，最后应用预测(models.predict)。问题的核心仍然在网络构建本身，但通过预定义的model（例如Dense, Activation）使得网络定义本身也得到了简化。</p>

<p>下面本文介绍下keras主要的应用模块。</p>

<p>1.layer本身相关部分</p>

<p>所有layer都有一些公有函数：
(1) get_weights() 返回层中神经元的权值，numpy.array
(2) set_weights() 设置层中神经元的权值
(3) get_config() 返回layer的配置</p>

<p>如果layer是非共享的，那么可以通过</p>

<pre><code>layer.input
layer.output
layer.input_shape
layer.output_shape
</code></pre>

<p>获取层的输入张量，输出张量，输入形状，输出形状。
如果layer是共享的，那么通过 get_xx_at(node_index) 获取指定node的信息。</p>

<p>(1)Dense：较常用的一种Neutral Network layer。</p>

<p>定义</p>

<pre><code>keras.layers.core.Dense(output\_dim, 
init='glorot\_uniform', activation='linear', weights=None ...)

主要参数：
output_dim：输出向量
input_dim：输入向量
activation: 定义传递函数，如果不指定，默认为linear, f(x)=x
</code></pre>

<p>调用实例，输入节点16个，输出节点32个：</p>

<pre><code>model = Sequential()
model.add(Dense(32, input_dim=16))
</code></pre>

<p>(2)Activation: 定义激活函数activation：</p>

<pre><code>keras.layers.core.Activation(activation)
</code></pre>

<p>输入层和输出层维度保持一致。</p>

<p>Dropout: 在模型训练的时候使得部分节点的权重不更新，包含参数p，取值范围是[0,1]，指定一定比例的训练样本不用于节点更新，避免过拟合。</p>

<pre><code>keras.layers.core.Dropout(p)

主要参数：
p：[0, 1], 指定一定比例的样本不用于更新
</code></pre>

<p>其它相关函数可以参考<a href="http://keras.io/layers/core/">这里</a>。</p>

<p>2.卷积相关layer定义
(1)Convolution1(/2/3)D ：卷积操作，分别针对1维、2维和3维的输入操作。</p>

<pre><code>keras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='uniform', activation='linear', weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)

主要参数：
nb_filter：指定卷积核的个数（等价于输出的维度）
卷积核的形状：
    一维是长度：filter_length
    二维是形状：nb_row, nb_col
    三维是形状：kernel_dim1/2/3
输入形状：
    一维例如：（10,30），前者是样本数量，后者是每个样本的维度
    二维例如：（3,256,256），前者是样本数量，后面两项是图像的长宽
</code></pre>

<p>(2)MaxPooling(&frac12;/3)D / AveragePooling(&frac12;/3)D：主要解释下pooling，它有点像是降采样，把一定区域内的特征按max或average的方法变为一个特征，用于降低处理的数据量。</p>

<p>3.optimizer</p>

<p>定义keras模型的优化方法，keras支持两种类型的输入，
(1) 指定optimizer类的实例，如：</p>

<pre><code>model = Sequential()
#...
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='mean_square_error', optimizer=sgd)
</code></pre>

<p>(2) 指定optimizer类的名称，如：</p>

<pre><code>model = Sequential()
model.compile(loss='mean_square_error', optimizer='sgd')
</code></pre>

<p>可选的optimizer方法包括SGD, RMSprop，Adagrad，Adadelta等，这些方法主要的区别在于learning rate的计算，learning rate作为超参数的一种，在早期的神经网络中并不能通过网络本身学习，而是通过使用者的经验（调参）决定，因此learning rate的计算方法本身也是深度学习重要的研究方向之一。简单的理解（或者说以我的理解），learning rate可以采取固定值（经验参数，策略一），也可以采用前期跨度大，后期跨度小（策略二），类似的不同策略衍生出不同的optimizer，更详细的科学解释可见<a href="https://www.quora.com/What-are-differences-between-update-rules-like-AdaDelta-RMSProp-AdaGrad-and-AdaM">这里</a>。</p>

<p>4.objective</p>

<p>定义keras模型的损失函数。同optimizer，keras也支持两种类型的输入：
(1) objective的名称，常用的如：</p>

<pre><code>mean_square_error/mse
binary_crossentropy
categorical_crossentropy
</code></pre>

<p>(2) Theano/TensorFlow的函数，类似<a href="https://github.com/fchollet/keras/blob/master/keras/objectives.py">如下</a>：</p>

<pre><code>def mean_squared_error(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)
</code></pre>

<p>5.activation</p>

<p>神经网络中的激活函数（=转移函数），常用的比如：</p>

<pre><code>model = Sequential()
model.add(Dense(64, activation='tanh'))
</code></pre>

<p>添加了tanh作为激活函数。这里同样可以传入函数对象：</p>

<pre><code>def tanh(x):
    return K.tanh(x)

model.add(Dense(64, activation=tanh))
model.add(Activation(tanh))
</code></pre>

<p>6.initializations</p>

<p>网络层的初始权值，不同层可以定义不同的权值分布，例如：</p>

<pre><code>model.add(Dense(64, init='uniform'))
</code></pre>

<p>定义一个包含64个节点，初始权值一致的网络层。</p>

<p>7.compile函数
objective和optimizer是compile函数必须的两项输入参数，例如：</p>

<pre><code>model = Sequential()
model.compile(loss='mean_square_error', optimizer='sgd')
</code></pre>
]]></content>
  </entry>
  
</feed>
