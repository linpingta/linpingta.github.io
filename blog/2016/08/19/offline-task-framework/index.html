
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>离线任务调度框架  | linpingta's blog</title>

	<meta name="author" content="linpingta"> 
	
	<meta name="description" content="这两天为项目需要写了个查询工具，想想还是有些东西可以提炼出来总结的，所以这篇来描述下我做的事情。 背景 首先，我们把广告主的数据做了汇总，最初的数据构建是为系统使用，并不是为用户数据分析使用的（为用户分析和为系统使用的区别，简单举个例子，用户分析关心账户的名称，系统只需要它的ID）， &hellip;"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="linpingta's blog" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	
</head>



<body>
	<header id="header" class="inner"><h1>linpingta's blog</h1>
<nav id="main-nav"><ul>
	<li><a href="/">Blog</a></li>
	<li><a href="/archives">Archive</a></li>
</ul>
</nav>


</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">离线任务调度框架</h2>
	<div class="entry-content"><p>这两天为项目需要写了个查询工具，想想还是有些东西可以提炼出来总结的，所以这篇来描述下我做的事情。</p>

<h2>背景</h2>

<p>首先，我们把广告主的数据做了汇总，最初的数据构建是为系统使用，并不是为用户数据分析使用的（为用户分析和为系统使用的区别，简单举个例子，用户分析关心账户的名称，系统只需要它的ID），但项目里想想既然都花时间做了数据，那索性给用户导出一些分析数据（ps，很理解，但从技术角度讲，导数据的辛苦程度相比做数据也不逞多让，尤其是我们的数据开始并不是为用户准备的，还好我在导出兴趣信息的时候多想想，不仅导出了ID，还导出来兴趣名称…）。</p>

<p>开始的需求是比较模糊的，可能是广告类型的投放分析，国家的投放分析，将来很可能会扩展和定制。</p>

<h2>设计目标</h2>

<p>原则上讲，每个查询需求实际都是对应一个hive查询。如果仅仅是处理目前报告的内容，最直接的方法是理解查询需求，然后写hive脚本，导出结果。</p>

<p>这样做虽然对少量的查询比较方便，但长远考虑，有明显的问题：</p>

<ol>
<li>Hive QL包含大量重复内容，按国家维度可能是查ctr, cpa，按性别维度也是，按年龄维度也是，如果不能保存查询语句，会浪费很多时间重敲语句</li>
<li>查询对用户不友好，因为查询都是要直接写Hive QL完成，一般非技术人员没有能力这样做，最终导致需求全部叠加到技术人员身上</li>
<li>查询效率不高，这里指的不是每条Hive QL语句（好吧为了突出优点有点拼，这里并没有对Hive QL本身的优化，在最后的缺点也会提到），而是多个查询本身是可以并行执行的，如果人工输入却不得不串行执行。尤其认真说，考虑到hive查询本身是比较慢的，等待时间并不十分乐观</li>
<li>Hive数据与导出数据不一致：这点看起来很小，但实际影响很大。虽然有很多查询可以直接使用Hive QL的输出，但还有一些查询需要再对原始数据做进一步的处理。举个例子，我们的国家是按 [A,B,C]保存的，但用户最终要的是国家A，B和C分别保存的信息，忽略或者特殊处理这种合并的情况，直接把hive查询结果返回是不能满足用户需求的</li>
<li>通用操作：比如结果展现给用户的形式，通过web界面，或者通过邮件，对不同的查询是通用的</li>
</ol>


<p>为解决上述问题，我在设计上考虑框架应该实现的几个属性</p>

<ol>
<li>任务化：把每个查询作为一个独立的任务对待，通过db ORM读取再处理，这样做主要是考虑将来可能和用户做交互时，用户的查询需要持久化</li>
<li><p>任务划分：</p>

<p>   Hive查询任务，更通用的说，是和db做交互的任务</p>

<p>   用户定义任务，基于Hive查询任务或其它用户定义任务，做类似ETL或者格式规范化方面的内容</p></li>
<li><p>信息抽取：主要是针对Hive查询任务，对每个查询语句都有select, from, tablename, where等，这些语法信息是用户不关心也无需了解的，让框架来完成这些通用的内容处理，用户只填写相关的信息</p></li>
<li>任务调度：hive查询是一个高IO低CPU的操作，可以通过多线程提高效率。同时由于用户定义任务对其它任务的依赖存在，这个调度变成比较经典的有向无环图（DAG）遍历问题</li>
<li>通用处理：我依赖pandas DataFrame作为数据存储的容器，每个hive查询任务的结果会被转为DataFrame再做持久化，用户依赖任务会依赖DataFrame做进一步操作（的确多了一次落盘读盘，后续考虑改进），DataFrame本身很方便的与csv文件做转换，以及对数据处理的强大支持（嗯还没有内存放不下的数据不用考虑分布式），也会方便后续的处理</li>
</ol>


<h2>框架流程</h2>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173204.jpg" alt="Framework" /></p>

<h2>实现</h2>

<ol>
<li>Task表定义</li>
</ol>


<p>基于Django的ORM定义，Task表里把Hive QL的基本组成部分做了独立的拆分，比如dimension, metric，为方便用户输入，这些字段采用json化的list或者list of dict，这些模块后续会由Task的引擎负责检查和拼装成正确的Hive QL</p>

<pre><code>Class QueryTask(models.Model):

    id = models.IntegerField(primary\_key=True)

    name = models.CharField(max\_length=255, blank=True)

    status = models.IntegerField(blank=True, null=True)

    paused = models.IntegerField(blank=True, null=True)

    dimension = models.CharField(max\_length=1024, blank=True)

    metric = models.CharField(max\_length=1024, blank=True)

    filter = models.CharField(max\_length=1024, blank=True)

    order = models.CharField(max\_length=1024, blank=True)

    tablename = models.CharField(max\_length=1024, blank=True)

    limit = models.IntegerField(blank=True, null=True)

    start\_dt = models.IntegerField(blank=True, null=True)

    end\_dt = models.IntegerField(blank=True, null=True)

    create\_time = models.IntegerField(blank=True, null=True)

parent\_task\_ids = models.CharField(max\_length=45, blank=True)
</code></pre>

<p>后续如果有用户交互的需求，可以把用户的查询保存到db，两边都通过ORM读写。在Django项目外使用modeles.py会有一些小坑，但都不算太大，这里不再描述。</p>

<ol>
<li>任务依赖执行</li>
</ol>


<p>有向无环图的多线程遍历，我依赖的是两个队列，未执行队列放入所有入度为0的任务，已执行队列保存所有执行完毕的任务。子线程负责从未执行队列里读取任务，执行任务，向完成队列里放入任务，主线程负责从已执行队列里取任务，减少对它依赖任务的入度，并将入度为0的任务放入未执行队列。</p>

<p><img src="/images/2016/8/QQ%E6%88%AA%E5%9B%BE20160819173500.jpg" alt="Iter" /></p>

<ul>
<li><p>HiveTask</p>

<p>引擎拼装HiveQL</p>

<p>查询执行</p>

<p>结果转换为DataFrame再做dump</p></li>
<li><p>UserDefineTask</p>

<p>加载依赖Task的DataFrame</p>

<p>数据处理，这里采用组合的方式，把任务的实际处理交给Worker来完成</p>

<p>保存数据</p></li>
</ul>


<h2>代码</h2>

<p><a href="https://github.com/linpingta/tools/tree/master/task_manager">Github task_manager</a></p>

<h2>问题</h2>

<p>作为一个粗糙的版本，虽然解决了开始提到的问题，但本身还是有很多的局限性：</p>

<ol>
<li>不支持table join，单个任务的查询数据只能来自一个table，这个是硬伤，对小项目可能还行，但大一点的查询就不够了。想想之前微策略做的就是根据table schema去构建table relationship，然后再封装成db无关的BI查询，还是挺敬仰的。</li>
<li>还是有很多项目耦合的内容在，比如HiveTask可以更一般化到DbTask，读取Task的方法可以考虑db之外更灵活的方式（比如xml），但这个的确是因为时间所限，还是以满足任务需求的扩展为主了。</li>
<li>用户定义任务通用内容的抽取：现在是通过把任务交给worker的方式解耦，但worker里的通用任务还不多，这点在后续的持续应用中应该会得到增加和改善。</li>
</ol>

</div>


<div class="meta">
	<div class="date">








  



<time datetime="2016-08-19T17:28:08+08:00" pubdate data-updated="true">Aug 19th, 2016</time></div>
	

<div class="tags">

	<a class='category' href='/blog/categories/github-project/'>github project</a>, <a class='category' href='/blog/categories/python/'>python</a>

</div>


</div>
</article>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2020
 linpingta 
<br>
Powered by Octopress.
</footer>
	

</body>
</html>
